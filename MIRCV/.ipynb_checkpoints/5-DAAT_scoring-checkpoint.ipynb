{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document-at-a-time Query Processing\n",
    "\n",
    "Implement document-at-a-time query processing using a simple scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "import pytest\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverted index\n",
    "\n",
    "For simplicity, the inverted index for the document collection is given as a dictionary, with a terms as keys and posting lists as values. Each posting is a (document ID, term frequency) tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {\n",
    "    \"beijing\": [        (1, 1),                 (4, 1)],\n",
    "    \"dish\":    [        (1, 1),                 (4, 1)],\n",
    "    \"duck\":    [(0, 3), (1, 2), (2, 2),         (4, 1)],\n",
    "    \"rabbit\":  [                (2, 1), (3, 1)        ],\n",
    "    \"recipe\":  [                (2, 1), (3, 1), (4, 1)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document lengths\n",
    "\n",
    "The length of each document is provided in a list (Normally, this information would be present in a document index).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_len = [3, 4, 4, 2, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-at-a-time scoring\n",
    "\n",
    "The retrieval function we use is the following:\n",
    "\n",
    "$$score(q,d) = \\sum_{t \\in q} w_{t,d} \\times w_{t,q}$$\n",
    "\n",
    "where $w_{t,d}$ and $w_{t,q}$ are length-normalized term frequencies, i.e., $w_{t,d} = \\frac{c_{t,d}}{|d|}$, where $c_{t,d}$ is the number of occurrences of term $t$ in document $d$ and $|d|$ is the document length, i.e., the total number of terms. Similarly for the query.\n",
    "\n",
    "We utilize the fact that the posting lists are ordered by document ID. Then, it's enough to iterate in parallel through term query term's posting list, and score the minimum docid at each iteration. We keep a pointer for each query term and we move it forward every time a docid is scored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an helper function that, given a dict of posting list pointers `pos`, returns the minimum docid. If all pointers go beyond the end of the corresponding posting list, we return `num_docs`, a special docid that it is guaranteed to not appear in any posting list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_docid(index: Dict[str, List[Tuple[int, int]]], \n",
    "              pos: Dict[str, int],\n",
    "              num_docs: int) -> int:\n",
    "    \"\"\"Returns the minimum docid across posting lists.\n",
    "    \n",
    "    Args:\n",
    "        index: Dict holding the inverted index.\n",
    "        pos: the current positions in the query posting lists.\n",
    "        num_docs: the number of indexed documents.\n",
    "    \n",
    "    Returns:\n",
    "        the minimum docid across the posting lists, or num_docs if all \n",
    "        postings in all posting lists have been processed.\n",
    "    \"\"\"\n",
    "    min_docid = num_docs\n",
    "\n",
    "    # For each query term posting list.\n",
    "    for term, pointer in pos.items():\n",
    "         # TODO: check if the posting list contains a valid docid; if so, update min_docid\n",
    "        docid = index[term][pointer][0]\n",
    "        if min_docid > docid:\n",
    "            min_docid = docid\n",
    "\n",
    "    for term, pointer in pos.items():\n",
    "        if index[term][pointer] == min_docid:\n",
    "           pointer += 1\n",
    "\n",
    "    # Return the min docid computed.\n",
    "    return min_docid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_collection(index: Dict[str, List[Tuple[int, int]]], \n",
    "                      doc_len: List[int], \n",
    "                      query: str) -> List[Tuple[int, float]]:\n",
    "    \"\"\"Scores all documents in the collection.\n",
    "    \n",
    "    Args:\n",
    "        index: Dict holding the inverted index.\n",
    "        doc_len: List with document lengths.\n",
    "        query: Search query.\n",
    "    \n",
    "    Returns:\n",
    "        List with (document_id, score) tuples, ordered by score desc.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Turns the query string into a \"term: freq\" dictionary.\n",
    "    query_freqs = dict(Counter(query.split()))\n",
    "\n",
    "    # Computes query length (i.e., sum of all query term frequencies).\n",
    "    query_len = sum(query_freqs.values())\n",
    "\n",
    "    doc_scores = {}  # Holds the final document scores (this should be a priority list, but for simplicity we use a dictionary here).\n",
    "    \n",
    "    pos = {term: 0 for term in query_freqs}  # Holds a pointer for each query term's posting list.\n",
    "    \n",
    "    # The starting docid.\n",
    "    docid = min_docid(index, pos, len(doc_len))\n",
    "    # While the posting lists have not been completely traversed.\n",
    "    while docid != len(doc_len):\n",
    "        score = 0.0\n",
    "        # TODO: DAAT scoring algorithm\n",
    "        for term, pointer in pos.items():\n",
    "            weight = index[term][pointer][1] / doc_len[docid]\n",
    "            partial_score = weight * (query_freqs[term] / query_len)\n",
    "            score += partial_score\n",
    "        doc_scores[docid] = score\n",
    "        # Update the docid.\n",
    "        docid = min_docid(index, pos, len(doc_len))\n",
    "    # TODO: return doc_scores sorted\n",
    "    return sorted(doc_scores.items(), key=lambda item: item[1],reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mF\u001b[0m\u001b[31m                                                                                            [100%]\u001b[0m\n",
      "============================================= FAILURES =============================================\n",
      "\u001b[31m\u001b[1m___________________________________________ test_scoring ___________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mtest_scoring\u001b[39;49;00m():\n",
      ">       scores = score_collection(index, doc_len, \u001b[33m\"\u001b[39;49;00m\u001b[33mbeijing duck recipe\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/jq/sxfhvkbn11s0jzgvkdhwp6v00000gn/T/ipykernel_2502/224187975.py\u001b[0m:2: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m/var/folders/jq/sxfhvkbn11s0jzgvkdhwp6v00000gn/T/ipykernel_2502/356543038.py\u001b[0m:26: in score_collection\n",
      "    docid = min_docid(index, pos, \u001b[96mlen\u001b[39;49;00m(doc_len))\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "index = {'beijing': [(1, 1), (4, 1)], 'dish': [(1, 1), (4, 1)], 'duck': [(0, 3), (1, 2), (2, 2), (4, 1)], 'rabbit': [(2, 1), (3, 1)], ...}\n",
      "pos = {'beijing': 0, 'duck': 0, 'recipe': 0}, num_docs = 5\n",
      "\n",
      "    \u001b[94mdef\u001b[39;49;00m \u001b[92mmin_docid\u001b[39;49;00m(index: Dict[\u001b[96mstr\u001b[39;49;00m, List[Tuple[\u001b[96mint\u001b[39;49;00m, \u001b[96mint\u001b[39;49;00m]]],\n",
      "                  pos: Dict[\u001b[96mstr\u001b[39;49;00m, \u001b[96mint\u001b[39;49;00m],\n",
      "                  num_docs: \u001b[96mint\u001b[39;49;00m) -> \u001b[96mint\u001b[39;49;00m:\n",
      "        \u001b[33m\"\"\"Returns the minimum docid across posting lists.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m        index: Dict holding the inverted index.\u001b[39;49;00m\n",
      "    \u001b[33m        pos: the current positions in the query posting lists.\u001b[39;49;00m\n",
      "    \u001b[33m        num_docs: the number of indexed documents.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns:\u001b[39;49;00m\n",
      "    \u001b[33m        the minimum docid across the posting lists, or num_docs if all\u001b[39;49;00m\n",
      "    \u001b[33m        postings in all posting lists have been processed.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "        min_docid = num_docs\n",
      "    \n",
      "        \u001b[90m# For each query term posting list.\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m term, pointer \u001b[95min\u001b[39;49;00m pos.items():\n",
      "             \u001b[90m# TODO: check if the posting list contains a valid docid; if so, update min_docid\u001b[39;49;00m\n",
      "            docid = index[term][pointer]\n",
      ">           \u001b[94mif\u001b[39;49;00m min_docid > docid:\n",
      "\u001b[1m\u001b[31mE           TypeError: '>' not supported between instances of 'int' and 'tuple'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m/var/folders/jq/sxfhvkbn11s0jzgvkdhwp6v00000gn/T/ipykernel_2502/4197059563.py\u001b[0m:21: TypeError\n",
      "===================================== short test summary info ======================================\n",
      "FAILED tmp6hocx9a6.py::test_scoring - TypeError: '>' not supported between instances of 'int' and...\n",
      "\u001b[31m\u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_scoring():\n",
    "    scores = score_collection(index, doc_len, \"beijing duck recipe\")    \n",
    "    assert scores[0][0] == 0\n",
    "    assert scores[0][1] == pytest.approx(1/3, rel=1e-2)\n",
    "    assert scores[2][0] == 2\n",
    "    assert scores[2][1] == pytest.approx(1/4, rel=1e-2)\n",
    "    assert scores[4][0] == 3\n",
    "    assert scores[4][1] == pytest.approx(1/6, rel=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c5e4a7eaa80b8b0cab0ebfd023b62b4fb81ced96acf97d50ef5e35c1384dc27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
